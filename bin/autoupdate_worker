#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Usage:
    autoupdate_worker --port <port> [options]

Arguments:
    <port> -- The port to run the server on.

Options:
    --logging (debug | info | error)
    --log_file <log_file> also log to a file
"""

from six.moves import BaseHTTPServer
import logging
import os.path
import os
import shutil
import subprocess
import tarfile
import time

import git
import gitenberg
import requests

from docopt import docopt
from gitenberg.util.catalog import Rdfcache
from gitenberg.config import ConfigFile

from gitenberg_autoupdate import __version__, ebooks, queue, util, webhooks

class RequestHandler(BaseHTTPServer.BaseHTTPRequestHandler):

    _rdfcache = None
    
    # login just once
    cache = {}

    def download_rdf(self):
        if not self._rdfcache:
            cf = ConfigFile()
            rdf_library = cf.data.get('rdf_library', None)
            self._rdfcache = Rdfcache(rdf_library=rdf_library)
        return self._rdfcache.download_rdf()

    def do_GET(self):
        if self.path != '/health':
            self.send_error(404)
            return
        
        # if the rdf cache ins't ready, we're not healthy
        if self.download_rdf():
            self.send_error(500, 'cache not ready')
            return

        # Claim we're alive and healthy if we're responding to this GET.
        self.send_response(200)
        self.end_headers()

    def do_POST(self):
        #try:
        if self.path != '/do_update':
            self.send_error(404)
            return

        if 'Content-Length' not in self.headers:
            self.send_error(400, 'no content-length')
            return

        content_length = int(self.headers['Content-Length'])
        payload_string = str(self.rfile.read(content_length), 'utf-8')
        logging.info('Got a message for %s' % payload_string)

        # First write something so that the nginx server upstream doesn't time out
        # even if building the book takes a while.
        self.wfile.write(bytes('%s ' % self.protocol_version, 'utf-8'))
        logging.info('%s ' % self.protocol_version)
        if self.download_rdf():
            self.send_error(500, 'rdf download failed')
            return

        if not process_queued_update(payload_string, cache=self.cache):
            self.send_error(500, 'update failed')
            return

        self.send_response(200)
        self.end_headers()

class cd:
    """Context manager for changing the current working directory"""
    def __init__(self, newPath):
        self.newPath = os.path.expanduser(newPath)

    def __enter__(self):
        self.savedPath = os.getcwd()
        os.chdir(self.newPath)

    def __exit__(self, etype, value, traceback):
        os.chdir(self.savedPath)

def make_ebook(b, tag):
    time0 = time.time()
    with cd(b.local_path):
        ebooks.build_epub()
        logging.info('epub for {} took {} seconds'.format(b.local_path, time.time() - time0))
        if os.path.exists("book.epub"):
            subprocess.check_call(('ebook-convert', 'book.epub', 'book.mobi'))
            subprocess.check_call(('xvfb-run', 'ebook-convert', 'book.epub', 'book.pdf'))
        logging.info('ebooks for {} took {} seconds'.format(b.local_path, time.time() - time0))
        ebooks.add_release(b, tag, ['book.epub', 'book.mobi', 'book.pdf'])

def ratelimit_remaining(book):
    try:
        return book.github_repo.github.ratelimit_remaining
    except:
        logging.error("couldn't get rate limit")
        return -1
        
def process_queued_update(repo_name, cache={}):
    repo_name_tag = [repo_name] if isinstance(repo_name, int) else repo_name.split(' ', 1)
    (repo_name, tag) = repo_name_tag if len(repo_name_tag) == 2 else (repo_name, None)
    # intialize book
    logging.info('getting: {}'.format(repo_name))
    b = gitenberg.actions.get_book(repo_name, cache=cache)
    ratelimit_start = ratelimit_remaining(b)
    logging.info('ratelimit_remaining[start]: {}'.format(ratelimit_remaining(b)))
    if b.local_path:
        b.remove()
    try:
        b.clone_from_github() # if no local version, clones

        # if it previously existed as a local repo, need to pull
        repo = b.local_repo.git
        if not repo.remote('origin'): # must exist
            logging.error("No origin for %s" % repo_name)
            return False
        repo.remote('origin').pull()

        commit_message = str(b.parse_book_metadata()) # in case this changed

        # checks for covers
        # if none, makes one, adds to metadata
        commit_message += str(b.add_covers()) # checks for covers

        if tag:
            b.meta.metadata['_version'] = tag
            commit_message += "tag {}".format(tag)

        b.save_meta() # save the new metadata in yaml format

        b.local_repo.add_all_files() # untracked only
        repo.git.add(update=True) # tracked ones too

        if repo.git.status("--porcelain"):
            logging.info('Have changes, so pushing and then building')
            # We made changes to the repo, so commit them.
            repo.index.commit(commit_message)

            # returns a list, one PushInfo per head. We have one head
            ret = repo.remote('origin').push(repo.refs.master)[0]
            if ret.flags & git.remote.PushInfo.ERROR:
                logging.error('Pushing returned %s' % ret)
                return False
        else:
            logging.info('No changes')
        if tag:
            make_ebook(b, tag) # make ebook files
            logging.info('Ebook Files made')
        
        ratelimit_end = ratelimit_remaining(b)
        logging.info("Used {} api calls; {} remaining".format(
            ratelimit_start - ratelimit_end, ratelimit_end
        ))
        return webhooks.gitensite(b) and webhooks.unglueit(b)
    finally:
        # Make sure to always remove it to avoid filling up the disk.
        if b.local_path:
            b.remove()

    return True

if __name__ == '__main__':
    arguments = docopt(__doc__, version=__version__)

    util.setup_logging(arguments)

    port = int(arguments.get('<port>', '80'))

    server = BaseHTTPServer.HTTPServer(('0.0.0.0', port), RequestHandler)
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        pass
    server.server_close()
